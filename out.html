<h1 id="forward">Forward</h1>
<p>I have structured this document to roughly coincide with a chronological account of 6 years spent in a neuro-oriented biomedical engineering lab. My role in the lab was centered around exploratory device design and development, mostly targeting application in neuroscience research, with intended users being neuroscientist colleagues. One of the lab’s most remarkable assets is the breadth and diversity of its constituents in terms of their skills and experience, both within and between the engineering/development and the science/medical sides of the lab. All efforts stood to benefit from the close proximity to skilled colleagues, most notably for the complementary guide and provide roles that assisted the development process of new devices and the experiments they were intended for.</p>
<p>My initial experience in optoelectronic device development was as an undergrad at Columbia University where I was advised by Elizabeth Hillman, and developed a device that combined thermography and near-infrared spectroscopy in a portable and inexpensive device intended to provide early detection of adverse neoplastic changes through at-home daily monitoring, particularly targeting use by patients with high-risk for breast cancer.</p>
<p>I then went to the Das Lab where I developed macroscopic imaging systems used for intrinsic imaging in the visual cortex of awake primates.</p>
<p>As a MD/PhD student, I attempt to maintain a potential to adapt the end-products of each development for clinical applicability.</p>
<p>The story presented here is rather unusual in that success precedes failure. The volume of tangible presentable results is greatest toward the beginning stages of the work described here. This unusual inversion is what make this story worth hearing, however. Thank you for taking the time to read this. I hope that at least the technical information provided herein, if not the procedural insight, is valuable in your current or future endeavors.</p>
<hr />
<h1 id="introduction">Introduction</h1>
<p>Most of this comes from the prospectus and the F31/NRSA application.</p>
<hr />
<h2 id="microscopy">Microscopy</h2>
<p>This section describes the background in microscopy in the neurosciences, and also how it relates to imaging in healthcare and electrophysiology in neuroscience. It will also describe the basic elements necessary for the construction of a microscope in a laboratory where calcium imaging in an animal is available. It will also refer to later sections which cover the design and construction of mechanical elements for animal handling and optical access (i.e. the headplate and a chronic optical window).</p>
<h3 id="filters">Filters</h3>
<h3 id="lenses">Lenses</h3>
<h3 id="mechanics">Mechanics</h3>
<h3 id="microscopy-and-functional-imaging-two-core-innovations-in-available">Microscopy and Functional Imaging Two core innovations in available</h3>
<ul>
<li>technology 1. Synthetic bio (i.e. GCaMP) 2. Cameras</li>
<li>scientific CMOS</li>
</ul>
<hr />
<h2 id="cameras-and-sensors">Cameras and Sensors</h2>
<p>This section details the evolution of cameras sensors and other sensors that provide bio-relevant data. Emphasis is on</p>
<hr />
<h2 id="sensors">Sensors</h2>
<h3 id="telemetry-control">Telemetry &amp; Control</h3>
<h3 id="scada-on-the-cheap">SCADA on the Cheap</h3>
<h3 id="development-boards">Development boards</h3>
<hr />
<h2 id="data-scaling">Data Scaling</h2>
<p>This section describes the reality of how data scales as more and more sensors are added. Typically we humans think linearly, but the ramifications of increasing something like sensor size is often exponential. Furthermore, many operations we perform have costs that scale exponentially, and in my humble opinion are not even worth attempting if any such procedure must applied continuously on a data=stream.</p>
<hr />
<h2 id="image-processing">Image Processing</h2>
<p>This section borrows from AIM-1 and AIM-2 of the prospectus.</p>
<h3 id="computing-power-and-connectivity">Computing Power and Connectivity</h3>
<ul>
<li>Remote Clusters (AWS)</li>
<li>Graphics Processing Units (NVIDIA GTX)</li>
<li>Embedded Units (NVIDIA Tegra X2) 2. Well developed libraries</li>
<li>ImageJ (so so)</li>
<li>OpenCV (uses OpenCL)</li>
<li>GStreamer (much better)</li>
<li>OpenGL</li>
<li>Shader</li>
</ul>
<h3 id="image-processing-1">Image Processing</h3>
<ul>
<li>Motion Correction</li>
<li>Image Enhancement</li>
</ul>
<h3 id="motion-correction-two-approaches-to-find-displacement">Motion Correction Two approaches to find displacement</h3>
<h3 id="spatially-homogeneous-phase-correlation">Spatially Homogeneous phase correlation</h3>
<ul>
<li>aka normalized cross correlation - Feature Matching</li>
<li>Detect features (i.e. corners) ### Triangulate best</li>
</ul>
<h3 id="image-enhancement">Image Enhancement</h3>
<ol type="1">
<li>Contrast - Linear Scaling - Lookup Tables</li>
<li>Spatial and Temporal Filtering</li>
<li>Feature images - Gradients</li>
</ol>
<h3 id="feature-extraction">Feature Extraction</h3>
<ol type="1">
<li>Feature images (temporally independent)</li>
</ol>
<ul>
<li>Gradients - Surface Curvature 2. Long Term Memory - Statistics - changes (single pixel)</li>
<li>Mutual information changes (inter-pixel)</li>
</ul>
<h3 id="acceleration-and-optimization-procedures-for-online-video-processing">Acceleration and Optimization Procedures for Online Video Processing</h3>
<h3 id="incremental-update-of-statistics">Incremental Update of Statistics</h3>
<h4 id="central-moments">central moments</h4>
<div class="sourceCode" id="cb1"><pre class="sourceCode matlab"><code class="sourceCode matlab"><a class="sourceLine" id="cb1-1" data-line-number="1">      function [m1,m2,m3,m4,fmin,fmax] = updateStatistics(x,m1,m2,m3,m4))</a>
<a class="sourceLine" id="cb1-2" data-line-number="2">            n = n + <span class="fl">1</span>;</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">            </a>
<a class="sourceLine" id="cb1-4" data-line-number="4">            <span class="co">% GET PIXEL SAMPLE</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5">            f = F(rowIdx,colIdx,k);</a>
<a class="sourceLine" id="cb1-6" data-line-number="6">            </a>
<a class="sourceLine" id="cb1-7" data-line-number="7">            <span class="co">% PRECOMPUTE &amp; CACHE SOME VALUES FOR SPEED</span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8">            d = single(f) - m1;</a>
<a class="sourceLine" id="cb1-9" data-line-number="9">            dk = d/n;</a>
<a class="sourceLine" id="cb1-10" data-line-number="10">            dk2 = dk^<span class="fl">2</span>;</a>
<a class="sourceLine" id="cb1-11" data-line-number="11">            s = d*dk*(n-<span class="fl">1</span>);</a>
<a class="sourceLine" id="cb1-12" data-line-number="12">            </a>
<a class="sourceLine" id="cb1-13" data-line-number="13">            <span class="co">% UPDATE CENTRAL MOMENTS</span></a>
<a class="sourceLine" id="cb1-14" data-line-number="14">            m1 = m1 + dk;</a>
<a class="sourceLine" id="cb1-15" data-line-number="15">            m4 = m4 + s*dk2*(n.^<span class="fl">2</span>-<span class="fl">3</span>*n+<span class="fl">3</span>) + <span class="fl">6</span>*dk2*m2 - <span class="fl">4</span>*dk*m3;</a>
<a class="sourceLine" id="cb1-16" data-line-number="16">            m3 = m3 + s*dk*(n-<span class="fl">2</span>) - <span class="fl">3</span>*dk*m2;</a>
<a class="sourceLine" id="cb1-17" data-line-number="17">            m2 = m2 + s;</a>
<a class="sourceLine" id="cb1-18" data-line-number="18">            </a>
<a class="sourceLine" id="cb1-19" data-line-number="19">            <span class="co">% UPDATE MIN &amp; MAX</span></a>
<a class="sourceLine" id="cb1-20" data-line-number="20">            fmin = min(fmin, f);</a>
<a class="sourceLine" id="cb1-21" data-line-number="21">            fmax = max(fmax, f);</a>
<a class="sourceLine" id="cb1-22" data-line-number="22">      end</a></code></pre></div>
<h4 id="extract-features">Extract Features</h4>
<div class="sourceCode" id="cb2"><pre class="sourceCode matlab"><code class="sourceCode matlab"><a class="sourceLine" id="cb2-1" data-line-number="1"></a>
<a class="sourceLine" id="cb2-2" data-line-number="2">      function [dm1,dm2,dm3,dm4] = getStatisticUpdate(x,m1,m2,m3,m4)</a>
<a class="sourceLine" id="cb2-3" data-line-number="3">            <span class="co">% COMPUTE DIFFERENTIAL UPDATE TO CENTRAL MOMENTS</span></a>
<a class="sourceLine" id="cb2-4" data-line-number="4">            dm1 = dk;</a>
<a class="sourceLine" id="cb2-5" data-line-number="5">            m1 = m1 + dm1;</a>
<a class="sourceLine" id="cb2-6" data-line-number="6">            dm4 = s*dk2*(n^<span class="fl">2</span>-<span class="fl">3</span>*n+<span class="fl">3</span>) + <span class="fl">6</span>*dk2*m2 - <span class="fl">4</span>*dk*m3;   </a>
<a class="sourceLine" id="cb2-7" data-line-number="7">            dm3 = s*dk*(n-<span class="fl">2</span>) - <span class="fl">3</span>*dk*m2;</a>
<a class="sourceLine" id="cb2-8" data-line-number="8">            dm2 = s;</a>
<a class="sourceLine" id="cb2-9" data-line-number="9">            m2 = m2 + dm2;</a>
<a class="sourceLine" id="cb2-10" data-line-number="10">            <span class="co">% NORMALIZE BY VARIANCE &amp; SAMPLE NUMBER -&gt; CONVERSION TO dVar, dSkew, dKurt   </span></a>
<a class="sourceLine" id="cb2-11" data-line-number="11">            dm2 = dm2/max(<span class="fl">1</span>,n-<span class="fl">1</span>);</a>
<a class="sourceLine" id="cb2-12" data-line-number="12">            dm3 = dm3*sqrt(max(<span class="fl">1</span>,n))/(m2^<span class="fl">1.5</span>);</a>
<a class="sourceLine" id="cb2-13" data-line-number="13">            dm4 = dm4*n/(m2^<span class="fl">2</span>);                 </a>
<a class="sourceLine" id="cb2-14" data-line-number="14">      end</a></code></pre></div>
<h3 id="simple-processing-on-gpu">Simple Processing on GPU</h3>
<div class="sourceCode" id="cb3"><pre class="sourceCode matlab"><code class="sourceCode matlab"><a class="sourceLine" id="cb3-1" data-line-number="1">      [dm1,dm2,dm3,dm4] = arrayfun(@getStatisticUpdate(x,m1,m2,m3,m4)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2">      [dm1,dm2,dm3,dm4] = arrayfun(@getStatisticUpdate(rowidx,colidx)</a></code></pre></div>
<h4 id="alternative-libraries">Alternative Libraries</h4>
<ul>
<li><a href="https://developer.nvidia.com/npp">NVIDIA Performance Primitives</a></li>
<li><a href="https://developer.nvidia.com/opencv">OpenCV</a></li>
<li><a href="http://www.vlfeat.org/">VLFeat</a></li>
<li>OpenGL</li>
<li>OpenCL</li>
<li>OpenVX</li>
<li>CLosedDoesNotExist (…?)</li>
<li>Shader Languages
<ul>
<li>GLSL</li>
<li>HLSL</li>
<li>WebGL</li>
<li>Halide</li>
<li></li>
</ul></li>
<li>FFmpeg</li>
<li>GStreamer</li>
</ul>
<h2 id="choice-of-interface">Choice of Interface</h2>
<h3 id="procedural-framework-pipes-streams-graphs">Procedural Framework: Pipes, Streams, &amp; Graphs</h3>
<h4 id="concurrency-parallel-performance">Concurrency: Parallel = Performance?</h4>
<p>Not always, no. While concurrent processing of independent tasks or sequentially arriving data elements will almost always increase performance, this is not always the case. At a lower instruction-level than we typically program, synchronous operations can often be optimized in ways that asynchronous operations cannot, typically through strategic register allocation, or by taking cache-hit performance). “Globally Asynchronous Locally Synchronous”</p>
<h4 id="scheduling">Scheduling</h4>
<h4 id="adaptive">Adaptive</h4>
<h3 id="choice-of-operations">Choice of Operations</h3>
<ul>
<li>What is the goal?</li>
<li>Is it effective?
<ul>
<li>Is the computation cost worth the result?</li>
</ul></li>
<li>Are there side-effects or artifacts?
<ul>
<li>Can they be reliably controlled or accounted for?</li>
</ul></li>
</ul>
<h3 id="motion-correction">Motion Correction</h3>
<p>In our application, the goal of a motion correction operation is to artificially suppress translation of the brain tissue parallel to the image plane. <em>Phase-Correlation</em> (also referred to as <em>normalized cross-correlation</em>) has consistent performance across a range of image sources with varying spatial noise characteristics. However, a large non-uniform change from reference frames - such as occurs when cells with low baseline fluourescence are first activated - can cause drastic errors that must be recognized and corrected by a supervisory procedure. This can induce an undesirable, unpredicatable, and specifically inopportune latency Unfortunately in all the whole pipeline.</p>
<p>Unfortunately, “Globally Asynchronous Locally Synchronous”</p>
<p>as it’s In some experimental setups,</p>
<p>The phase correlation method of #### Motion Estimation - cost: 2-10 ms/frame - Frequently unstable (depending on video content)</p>
<h4 id="motion-compensation-interpolation">Motion Compensation &amp; Interpolation</h4>
<ul>
<li>cost: 400-800 us/frame</li>
<li>Requires infill with nearby or prior pixel values if frame size is to be maintained</li>
</ul>
<p>###Survey of Alternative Strategies</p>
<h3 id="implementation">Implementation</h3>
<h3 id="efficientcode">EfficientCode</h3>
<ul>
<li>Scalable - Reusable - Make it MODULAR</li>
<li></li>
</ul>
<h3 id="operation">Operation</h3>
<hr />
<h2 id="video-processing">Video Processing</h2>
<p>This section borrows from AIM-1 and AIM-2 from the prospectus.</p>
<h3 id="effective-and-efficient-code">Effective and Efficient Code</h3>
<hr />
<h2 id="biomimicry-in-visual-processing">Biomimicry in Visual Processing</h2>
<p>This section describes how image and video processing in the computer relate to visual processing in the mammalian brain. The overall goal is to emphasize the advantage and importance of biomimetic development.</p>
<hr />
<h2 id="distributed-dataflow-and-streaming">Distributed Dataflow and Streaming</h2>
<h3 id="choice-of-implementation">Choice of Implementation</h3>
<h3 id="language-is-matlab-the-best-tool-for-this-job">Language: Is MATLAB the best tool for this job?</h3>
<ul>
<li>Standard language in many engineering programs</li>
<li>Proprietary</li>
<li>Performance</li>
<li>Compatibility</li>
<li>Need for a “SandBox”</li>
<li>Lacks modularity</li>
<li></li>
</ul>
<h3 id="alternatives-languages">Alternatives Languages</h3>
<ul>
<li>Python</li>
<li>C/C++</li>
<li>Java/Scala</li>
<li>Javascript/Node</li>
<li>GO, Haskell</li>
</ul>
<h3 id="databases">Databases</h3>
<h3 id="big-data">Big Data</h3>
<ul>
<li>not exactly...</li>
<li>disparate simple queries across</li>
</ul>
<h3 id="map-reduce">Map-Reduce</h3>
<ul>
<li>Dataflow Processing</li>
<li>Actors model</li>
<li>Petri Nets</li>
<li>Graph Processing - i.e. Tensorflow</li>
</ul>
<hr />
<h2 id="software-for-procedure-development">Software for Procedure Development</h2>
<h3 id="development-environment">Development Environment</h3>
<hr />
<h2 id="information-and-informativity">Information and Informativity</h2>
<p>This section presents a background in information theory in the context of behavior sensors and video streams. I further elaborate on what types of information neuroscientists and healthcare providers would hope to extract from these data, focusing on a larger picture of connecting the process of extraction directly the ultimate application.</p>
<p>Whereas previous attempts to process data focus largely on putting it in an intermediate state that is workable with current limitations on computation, visualization, and developer interaction with the data-streams, we now have an opportunity to skip intermediate states and develop with applications in mind.</p>
<p>Transition into compression by showing that previous attempts were essentially compression algorithms developed specifically for the data and preconceived notions about results, but that we can also apply very well developed general compression algorithms, with slight modifications to extract features such as localized bitrate that quantify (in an unbiased way) information content in an selectable region of a video-frame as it changes over time.</p>
<hr />
<h2 id="compression-as-a-tool-a-goal-as-an-explanation">Compression: as a Tool, a Goal, as an Explanation</h2>
<p>This section describes general compression algorithms as well as compression algorithms specifically tailored to application in video, accomplished by searching for both temporal and spatial redunancy.</p>
<hr />
<h2 id="acknowledgements">Acknowledgements</h2>
<p>The support and patience I have received from my committee has gone far beyond what should be expected of anyone. I can’t thank you enough. * Xue Han, Ph.D. * Jerome Mertz, Ph.D. * Ian Davis, Ph.D. * Tom Bifano, Ph.D. * David Boas, Ph.D.</p>
<hr />
